{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow \n",
    "\n",
    "Machine learning frameworks like TensorFlow, PaddlePaddle, Torch, Caffe, Keras, and many others can speed up the machine learning development significantly when compared to building the algorithms in python.Programing frameworks can not only shorten your coding time, but sometimes also perform optimizations that speed up your code. In this notebook,we experiment with the  following in TensorFlow: \n",
    "\n",
    "- Compute a linear function\n",
    "- Compute sigmoid function\n",
    "- Compute cost for neural networks\n",
    "- Create one hot encoding matrix\n",
    "- Initialize a vector of zeros and ones.\n",
    "- Implement a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing tensor flow libraries\n",
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing and running programs in TensorFlow has the following steps:\n",
    "\n",
    "1. Create Tensors (variables) that are not yet executed/evaluated. \n",
    "2. Write operations between those Tensors.\n",
    "3. Initialize your Tensors. \n",
    "4. Create a Session. \n",
    "5. Run the Session. This will run the operations you'd written above. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Linear function\n",
    "\n",
    "We compute the following equation: $Y = WX + b$, where $W$ and $X$ are random matrices and b is a random vector. \n",
    "W is of shape (4, 3), X is (3,1) and b is (4,1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_function():\n",
    "    \"\"\"\n",
    "    Implements a linear function: \n",
    "            Initializes W to be a random tensor of shape (4,3)\n",
    "            Initializes X to be a random tensor of shape (3,1)\n",
    "            Initializes b to be a random tensor of shape (4,1)\n",
    "    Returns: \n",
    "    result -- runs the session for Y = WX + b \n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(123)\n",
    "    \n",
    "\n",
    "    X = tf.constant(np.random.randn(3,1),name=\"X\")\n",
    "    W = tf.constant(np.random.randn(4,3),name=\"W\")\n",
    "    b = tf.constant(np.random.randn(4,1),name=\"b\")\n",
    "    Y = tf.constant(np.random.randn(4,1))\n",
    " \n",
    "    \n",
    "    # Creating the session using tf.Session() and running it with sess.run(...) on the variable we want to calculate\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(tf.add(tf.matmul(W,X),b))\n",
    "    ### END CODE HERE ### \n",
    "    \n",
    "    # close the session \n",
    "    sess.close()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = [[ 1.09118507]\n",
      " [ 4.77086602]\n",
      " [ 2.42386138]\n",
      " [-1.37788767]]\n"
     ]
    }
   ],
   "source": [
    "print( \"result = \" + str(linear_function()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Sigmoid \n",
    "Tensorflow offers a variety of commonly used neural network functions like `tf.sigmoid` and `tf.softmax`.We implement sigmoid for our learning purpose \n",
    "\n",
    "Note that there are two typical ways to create and use sessions in tensorflow: \n",
    "\n",
    "**Method 1:**\n",
    "```python\n",
    "sess = tf.Session()\n",
    "# Run the variables initialization (if needed), run the operations\n",
    "result = sess.run(..., feed_dict = {...})\n",
    "sess.close() \n",
    "# Close the session\n",
    "```\n",
    "**Method 2:**\n",
    "```python\n",
    "with tf.Session() as sess: \n",
    "    # run the variables initialization (if needed), run the operations\n",
    "    result = sess.run(..., feed_dict = {...})\n",
    "    # This takes care of closing the session for you\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Computes the sigmoid of z\n",
    "    \n",
    "    Arguments:\n",
    "    z -- input value, scalar or vector\n",
    "    \n",
    "    Returns: \n",
    "    results -- the sigmoid of z\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a placeholder for x. Name it 'x'.\n",
    "    x = tf.placeholder(tf.float32,name=\"x\")\n",
    "\n",
    "    # compute sigmoid(x)\n",
    "    sigmoid = tf.sigmoid(x)\n",
    "\n",
    "    # Creating a session, and running it. \n",
    "    #Using the method 2 explained above. \n",
    "       \n",
    "    with tf.Session() as sess:\n",
    "            result = sess.run(sigmoid,feed_dict={x: z})\n",
    "    \n",
    "       \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(0) = 0.5\n",
      "sigmoid(12) = 0.999994\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))\n",
    "print (\"sigmoid(12) = \" + str(sigmoid(12)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Computing the Cost\n",
    "\n",
    "Instead of needing to write code to compute the cost as a function of $a^{[2](i)}$ and $y^{(i)}$ for i=1...m: \n",
    "$$ J = - \\frac{1}{m}  \\sum_{i = 1}^m  \\large ( \\small y^{(i)} \\log a^{ [2] (i)} + (1-y^{(i)})\\log (1-a^{ [2] (i)} )\\large )\\small\\tag{1}$$\n",
    "\n",
    "we can do it in one line of code in tensorflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(logits, labels):\n",
    "    \"\"\"\n",
    "    Computes the cost using the sigmoid cross entropy\n",
    "    \n",
    "    Arguments:\n",
    "    logits -- vector containing z, output of the last linear unit (before the final sigmoid activation)\n",
    "    labels -- vector of labels y (1 or 0) \n",
    "    \n",
    "    Note: logits will feed into z, and labels into y. \n",
    "    \n",
    "    Returns:\n",
    "    cost -- runs the session of the cost (formula (1))\n",
    "    \"\"\"\n",
    "\n",
    "    # Creating the placeholders for \"logits\" (z) and \"labels\" (y) \n",
    "    z = tf.placeholder(tf.float32,name=\"z\")\n",
    "    y = tf.placeholder(tf.float32,name=\"y\")\n",
    "    \n",
    "    # Using the loss function \n",
    "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits=z,labels=y)\n",
    "    \n",
    "    # Creating a session \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Running the session \n",
    "    cost = sess.run(cost,feed_dict={z: logits,y: labels})\n",
    "    \n",
    "    # Closing the session \n",
    "    sess.close()\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = [ 1.00538719  1.03664076  0.41385433  0.39956617]\n"
     ]
    }
   ],
   "source": [
    "logits = sigmoid(np.array([0.2,0.4,0.7,0.9]))\n",
    "cost = cost(logits, np.array([0,0,1,1]))\n",
    "print (\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  One Hot encodings\n",
    "\n",
    "Many times we encounter a y vector with numbers ranging from 0 to C-1, where C is the number of classes.We convert this vector using a technique called \"one hot\" encoding,where the converted representation had exactly one element of each column as \"hot\" (meaning set to 1). To do this conversion in numpy, we might have to write a few lines of code. In tensorflow, we can use one line of code: \n",
    "\n",
    "- tf.one_hot(labels, depth, axis) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "     \n",
    "    # Creating a tf.constant equal to C (depth), name it 'C'. \n",
    "    C = tf.constant(C,name=\"C\")\n",
    "    \n",
    "    # Using tf.one_hot\n",
    "    one_hot_matrix = tf.one_hot(labels,C,axis=0)\n",
    "    \n",
    "    # Creating the session \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Running the session \n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot = [[ 0.  0.  0.  1.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  1.]\n",
      " [ 0.  1.  0.  0.  1.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, C = 4)\n",
    "print (\"one_hot = \" + str(one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize with zeros and ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ones(shape):\n",
    "    \"\"\"\n",
    "    Creates an array of ones of dimension shape\n",
    "    \n",
    "    Arguments:\n",
    "    shape -- shape of the array you want to create\n",
    "        \n",
    "    Returns: \n",
    "    ones -- array containing only ones\n",
    "    \"\"\"\n",
    "    \n",
    "       \n",
    "    # Creating \"ones\" tensor using tf.ones(...).\n",
    "    ones = tf.ones(shape)\n",
    "    \n",
    "    # Creating the session \n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Running the session to compute 'ones' \n",
    "    ones = sess.run(ones)\n",
    "    sess.close()\n",
    "\n",
    "    return ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones = [ 1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print (\"ones = \" + str(ones([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a neural network in tensorflow\n",
    "\n",
    "### Problem statement: SIGNS Dataset\n",
    "\n",
    "Then problem statement and the dateset is borrowed form the course assignment in Improving Deep Neural Nets(Coursera) by Andrew Ng.\n",
    "\n",
    "One afternoon, with some friends we decided to teach our computers to decipher sign language. We spent a few hours taking pictures in front of a white wall and came up with the following dataset. It's now your job to build an algorithm that would facilitate communications from a speech-impaired person to someone who doesn't understand sign language.\n",
    "\n",
    "- **Training set**: 1080 pictures (64 by 64 pixels) of signs representing numbers from 0 to 5 (180 pictures per number).\n",
    "- **Test set**: 120 pictures (64 by 64 pixels) of signs representing numbers from 0 to 5 (20 pictures per number).\n",
    "\n",
    "Note that this is a subset of the SIGNS dataset. The complete dataset contains many more signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTq+hSm5eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a777e7c048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 12\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "We implement the following pre processing steps:\n",
    "\n",
    "- Flatten the image dataset\n",
    "- Normalize it by dividing by 255. \n",
    "- Convert each label to a one-hot vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (12288, 1080)\n",
      "Y_train shape: (6, 1080)\n",
      "X_test shape: (12288, 120)\n",
      "Y_test shape: (6, 120)\n"
     ]
    }
   ],
   "source": [
    "# Flattening the training and test images\n",
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "# Normalizing image vectors\n",
    "X_train = X_train_flatten/255.\n",
    "X_test = X_test_flatten/255.\n",
    "\n",
    "# Converting training and test labels to one hot matrices\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6)\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6)\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our goal** is to build an algorithm capable of recognizing a sign with high accuracy. To do so, we are going to build a tensorflow model.\n",
    "\n",
    "**The model** is *LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX*. We use oftmax as an output layer because a softmax layer generalizes SIGMOID to when there are more than two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(tf.float32,shape=(n_x,None))\n",
    "    Y = tf.placeholder(tf.float32,shape=(n_y,None))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(12288, ?), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(12288, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the parameters\n",
    "\n",
    "Your second task is to initialize the parameters in tensorflow using Xavier Initialization for weights and Zero Initialization for biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [25, 12288]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [6, 12]\n",
    "                        b3 : [6, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(123)                  \n",
    "\n",
    "    W1 = tf.get_variable(\"W1\", [25,12288], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [25,1],initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [12,25], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [12,1],initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [6,12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [6,1],initializer = tf.zeros_initializer())\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = <tf.Variable 'W1:0' shape=(25, 12288) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters haven't been evaluated yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propagation in tensorflow \n",
    "\n",
    "We will now implement the forward propagation module in tensorflow. The function will take in a dictionary of parameters and it will complete the forward pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieving the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "                                                                    # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                                 # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                             # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                                # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                             # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                                 # Z3 = np.dot(W3,Z2) + b3\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 = Tensor(\"Add_2:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(12288, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    print(\"Z3 = \" + str(Z3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "   \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(12288, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Backward propagation & parameter updates\n",
    "\n",
    "After we compute the cost function, we will create an \"`optimizer`\" object. We have to call this object along with the cost when running the tf.session. When called, it will perform an optimization on the given cost with the chosen method and learning rate.\n",
    "\n",
    "For instance, for gradient descent the optimizer would be:\n",
    "```python\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "```\n",
    "\n",
    "To make the optimization we would do:\n",
    "```python\n",
    "_ , c = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "```\n",
    "\n",
    "This computes the backpropagation by passing through the tensorflow graph in the reverse order. From cost to inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function for random mini batches\n",
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "        \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Building the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(123)                            \n",
    "    seed = 123                                          \n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X,Y = create_placeholders(n_x,n_y)\n",
    " \n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "  \n",
    "    \n",
    "    # Forward propagation: Building the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(X,parameters)\n",
    "  \n",
    "    #Cost function: Adding cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3,Y)\n",
    " \n",
    "    \n",
    "    # Backpropagation: Defining the tensorflow optimizer.\n",
    "    #Using an AdamOptimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initializing all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Starting the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(init)\n",
    "        \n",
    "        #  training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # Running the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "               \n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "               \n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Printing the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # ploting the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculating the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculating accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Run the following cell to train your model! On our machine it takes about 5 minutes. Your \"Cost after epoch 100\" should be 1.016458. If it's not, don't waste time; interrupt the training by clicking on the square (⬛) in the upper bar of the notebook, and try to correct your code. If it is the correct cost, take a break and come back in 5 minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 1.882616\n",
      "Cost after epoch 100: 1.028612\n",
      "Cost after epoch 200: 0.715003\n",
      "Cost after epoch 300: 0.543989\n",
      "Cost after epoch 400: 0.436578\n",
      "Cost after epoch 500: 0.368672\n",
      "Cost after epoch 600: 0.285531\n",
      "Cost after epoch 700: 0.243357\n",
      "Cost after epoch 800: 0.188955\n",
      "Cost after epoch 900: 0.153733\n",
      "Cost after epoch 1000: 0.122976\n",
      "Cost after epoch 1100: 0.104146\n",
      "Cost after epoch 1200: 0.083846\n",
      "Cost after epoch 1300: 0.063842\n",
      "Cost after epoch 1400: 0.046236\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcHVWZ//HP0/veSaeX7PsOhAAxYScgYII4EUUFERTR\nTEAcndERGGfUwcGfgzquIAJiVBQGh1X2HcISSCdk38na2TrpJJ1O78vz+6MqcGm6OzdJ3763u7/v\n16te996qU3WfQ4X79Dl16pS5OyIiIoeTFO8ARESke1DCEBGRqChhiIhIVJQwREQkKkoYIiISFSUM\nERGJihKG9Ghm9pSZfTHecYj0BEoYEhNmtsnMzo93HO4+093/GO84AMzsZTP7Shd8T7qZ3WNmB8xs\np5n9y2HKf97MNptZtZk9YmYF0R7LzCab2UIzqwlfJ0dsO97MnjGzPWamG756ACUM6bbMLCXeMRyS\nSLEAPwDGAMOAc4HvmNmMtgqa2XHA74ArgRKgBrg9mmOZWRrwKHAv0Bf4I/BouB6gEXgAuKbzqiZx\n5e5atHT6AmwCzm9n28XAYmA/8AYwKWLbjcC7QBWwErgkYtuXgNeBnwMVwH+F614DfgrsAzYCMyP2\neRn4SsT+HZUdAbwafvfzwG3Ave3UYTpQBtwA7AT+TPCj+TiwOzz+48DgsPwtQDNQBxwEfhOuHw88\nB+wF1gCf7YT/9tuBCyM+3wzc307ZHwF/jfg8CmgAcg93LOBCYBtgEdu3ADNafcfo4Kcm/v8utRzb\nohaGdCkzOwm4B/hHoB/BX7ePmVl6WORd4CwgH/hP4F4zGxBxiGnABoK/hm+JWLcGKARuBX5vZtZO\nCB2V/SvwdhjXDwj+6u5If6CA4K/v2QQt9j+En4cCtcBvANz9u8A84Hp3z3H3680smyBZ/BUoBi4D\nbjeziW19mZndbmb721mWhmX6AgOAJRG7LgGOa6cOx0WWdfd3gXpgbBTHOg5Y6mFWiOK7pJtTwpCu\nNhv4nbu/5e7NHlxfqAdOBXD3v7n7dndvcff/BdYBUyP23+7uv3b3JnevDddtdve73L2ZoFtkAEFC\naUubZc1sKPAR4Hvu3uDurwGPHaYuLcD33b3e3WvdvcLdH3T3GnevIkho53Sw/8XAJnf/Q1ifd4AH\ngc+0Vdjdr3P3Pu0sk8JiOeFrZcSuB4DcdmLIaVU2svzhjtXRvtIDKWFIVxsGfCvyr2NgCDAQwMyu\nMrPFEduOJ2gNHLK1jWPuPPTG3WvCtzltlOuo7EBgb8S69r4r0m53rzv0wcyyzOx34QXkAwTdW33M\nLLmd/YcB01r9t7iCoOVytA6Gr3kR6/IJutnaK5/Xat2h8oc7Vkf7Sg+khCFdbStwS6u/jrPc/T4z\nGwbcBVwP9HP3PsByILJ7KVajbXYABWaWFbFuyGH2aR3Lt4BxwDR3zwPODtdbO+W3Aq+0+m+R4+7X\ntvVlZnaHmR1sZ1kB4O77wrqcGLHricCKduqwIrKsmY0C0oC1URxrBTCpVfffpA6+S7o5JQyJpVQz\ny4hYUggSwhwzm2aBbDP7uJnlAtkEP6q7AczsaoIWRsy5+2agFPiBmaWZ2WnAJ47wMLkE1y32h0NT\nv99q+y5gZMTnxwmuFVxpZqnh8hEzm9BOjHPChNLWEnnd4E/Av5tZ3/BYXwXmthPzX4BPmNlZ4TWV\nHwIPhV1qhzvWywQX8v8pHH77TwTn70WA8PxmECQgwn8Dh65VSTekhCGx9CTBD+ih5QfuXkrwo/Mb\ngpFE6wlGL+HuK4GfAW8S/LieQDAqqqtcAZzG+yOw/pfg+kq0fgFkAnuA+cDTrbb/ErjUzPaZ2a/C\nH+ULCS52byfoLvtv4Fh/VL9PMHhgM8GP+q3u/l4sYYvkLAB3XwHMIUgc5QRJ+7pojuXuDcAngasI\nRrx9CfhkuB6CLrda3m9x1BIMOJBuyj44wEFEDjGz/wVWu3vrloJIr6QWhkgo7A4aZWZJ4c1ps4BH\n4h2XSKJIpLtTReKtP/AQwX0YZcC14VBXEUFdUiIiEiV1SYmISFR6VJdUYWGhDx8+PN5hiIh0GwsX\nLtzj7kXRlO1RCWP48OGUlpbGOwwRkW7DzDZHW1ZdUiIiEhUlDBERiYoShoiIREUJQ0REoqKEISIi\nUVHCEBGRqChhiIhIVHp9wnB3fv3COl5ZuzveoYiIJLRenzDMjDvnbeCl1eXxDkVEJKH1+oQBUJST\nzu6DR/KcHBGR3kcJAyjMTWd3lRKGiEhHlDCAotx09ihhiIh0SAmDsEtKCUNEpENKGAQtjKr6Juoa\nm+MdiohIwlLCIEgYgFoZIiIdUMIg6JICNFJKRKQDShiohSEiEg0lDJQwRESioYQBFGSnYaaEISLS\nkZg909vM7gEuBsrd/fg2tv8rcEVEHBOAInffa2abgCqgGWhy9ymxihMgNTmJopx0yvbVxvJrRES6\ntVi2MOYCM9rb6O4/cffJ7j4ZuAl4xd33RhQ5N9we02RxyJiSHNbvPtgVXyUi0i3FLGG4+6vA3sMW\nDFwO3BerWKIxpjiX9buqcPd4hiEikrDifg3DzLIIWiIPRqx24HkzW2hmsw+z/2wzKzWz0t27j36K\n8tHFOVQ3NLO9su6ojyEi0pPFPWEAnwBeb9UddWbYVTUT+JqZnd3ezu5+p7tPcfcpRUVFRx3E2JJc\nANbtqjrqY4iI9GSJkDAuo1V3lLtvC1/LgYeBqbEOYkxxDgDry3UdQ0SkLXFNGGaWD5wDPBqxLtvM\ncg+9By4Elsc6lr7ZaRTmpLFulxKGiEhbYjms9j5gOlBoZmXA94FUAHe/Iyx2CfCsu1dH7FoCPGxm\nh+L7q7s/Has4I40uzmFdubqkRETaErOE4e6XR1FmLsHw28h1G4ATYxNVx8YU5/LI4m24O2HCEhGR\nUCJcw0gYY0tyqKprYtcB3fEtItKaEkaE0cXhSCl1S4mIfIgSRoQxJcFIKV34FhH5MCWMCP2y0+ib\nlaoWhohIG5QwIpgZY0tyWasWhojIhyhhtDKufy5rd2pOKRGR1pQwWhlbkktVfZPmlBIRaUUJo5Xx\n/YORUmt36jqGiEgkJYxWxoSTEK7RJIQiIh+ghNFKfmYqA/Iz1MIQEWlFCaMNY0ty1cIQEWlFCaMN\n4/rnsq78IM0tGiklInKIEkYbxpbk0tDUwqaK6sMXFhHpJZQw2jCuRCOlRERaU8Jow+jiHMw0UkpE\nJJISRhsy05IZVpDFGrUwRETeo4TRjvH985QwREQiKGG0Y1z/XDZVVFPb0BzvUEREEkLMEoaZ3WNm\n5Wa2vJ3t082s0swWh8v3IrbNMLM1ZrbezG6MVYwdGd8/lxbXw5RERA6JZQtjLjDjMGXmufvkcLkZ\nwMySgduAmcBE4HIzmxjDONs0fkAeAKvVLSUiAsQwYbj7q8Deo9h1KrDe3Te4ewNwPzCrU4OLwtCC\nLDJSk1i9QwlDRATifw3jdDNbamZPmdlx4bpBwNaIMmXhujaZ2WwzKzWz0t27d3daYMlJxqRBfXhr\nY0WnHVNEpDuLZ8JYBAx190nAr4FHjuYg7n6nu09x9ylFRUWdGuB5E4pZsf0A2/fXdupxRUS6o7gl\nDHc/4O4Hw/dPAqlmVghsA4ZEFB0cruty508oBuCF1eXx+HoRkYQSt4RhZv3NzML3U8NYKoAFwBgz\nG2FmacBlwGPxiHFUUQ5DC7KYt7bzurpERLqrlFgd2MzuA6YDhWZWBnwfSAVw9zuAS4FrzawJqAUu\n8+BB2k1mdj3wDJAM3OPuK2IVZ0fMjBMG57OsrDIeXy8iklBiljDc/fLDbP8N8Jt2tj0JPBmLuI7U\nhP65PLF0B1V1jeRmpMY7HBGRuIn3KKmEN75/cD/GWk1EKCK9nBLGYYwfEEx1vkr3Y4hIL6eEcRiD\n+mSSm57Cqh0H4h2KiEhcKWEchpkxNnxkq4hIb6aEEYVRRdls2K3HtYpI76aEEYWRRTnsOVjPgbrG\neIciIhI3ShhRGFmYDaBWhoj0akoYURhZlAPAht26jiEivZcSRhSG9csiJcnUwhCRXk0JIwqpyUkM\n7ZfFkrL98Q5FRCRulDCi9OmTBzNv3R5eWqOZa0Wkd1LCiNJXzhrB0IIs7np1Q7xDERGJCyWMKKWn\nJHP6qH6s2nGAYFJdEZHeRQnjCIwtyWVfTSO7D9bHOxQRkS6nhHEExvcPJiJcs1MTEYpI76OEcQTG\nKWGISC+mhHEE+uWkU5iTpoQhIr2SEsYRmjgwn8VbdT+GiPQ+MUsYZnaPmZWb2fJ2tl9hZkvNbJmZ\nvWFmJ0Zs2xSuX2xmpbGK8WicMaof68oPsrOyLt6hiIh0qVi2MOYCMzrYvhE4x91PAH4I3Nlq+7nu\nPtndp8QovqNy5phCAF5bvyfOkYiIdK2YJQx3fxXY28H2N9x9X/hxPjA4VrF0pgn98+iXncZr63bH\nOxQRkS6VKNcwrgGeivjswPNmttDMZne0o5nNNrNSMyvdvTv2P+JJScaZYwp5bf0eWlp0A5+I9B5x\nTxhmdi5BwrghYvWZ7j4ZmAl8zczObm9/d7/T3ae4+5SioqIYRxsGN7qQPQcbWK3RUiLSi8Q1YZjZ\nJOBuYJa7Vxxa7+7bwtdy4GFganwibNtZY4LENE/dUiLSi8QtYZjZUOAh4Ep3XxuxPtvMcg+9By4E\n2hxpFS/98zMYU5zDU8t3qltKRHqNWA6rvQ94ExhnZmVmdo2ZzTGzOWGR7wH9gNtbDZ8tAV4zsyXA\n28AT7v50rOI8WtecOYLFW/fzpzc3xTsUEZEuYT1p5tUpU6Z4aWnX3Lbh7lx+13zK9tXy2g3ndcl3\nioh0NjNbGO3tC3G/6N1dmRkXTOxP2b5adlTWxjscEZGYU8I4BlOHFwDw9sZ2bzcREekxlDCOwYQB\nuWSnJbNgkxKGiPR8ShjHICU5iVOGF/DGuxWHLywi0s0pYRyjCyYUs2F3Net26SY+EenZlDCO0ceO\n648ZPLlsZ7xDERGJKSWMY1Scl8GUYX15Ytn2eIciIhJTShid4B9OHMjaXQdZteNAvEMREYkZJYxO\n8PFJA0lJMh5ZvC3eoYiIxIwSRicoyE7jnLFFPLZ4u+aWEpEeSwmjk8w6aRA7Kut4SzfxiUgPpYTR\nSS6YUEJ2WjKPvKNuKRHpmZQwOklmWjIfO74/Ty7fQUNTS7zDERHpdEoYnegTkwZSVdekByuJSI+k\nhNGJzhhdSF5GCk8s3RHvUEREOp0SRidKS0li5vEDeGr5TvbXNMQ7HBGRTqWE0cmuPnM4tY3N/OnN\nzfEORUSkU0WVMMzsM9Gsa7X9HjMrN7M2n8dtgV+Z2XozW2pmJ0dsm2Fma8JtN0YTY6IY3z+P88YX\nc8/rG9lbrVaGiPQc0bYwbopyXaS5wIwOts8ExoTLbOC3AGaWDNwWbp8IXG5mE6OMMyHcMGM8B+ua\n+O+nVsc7FBGRTpPS0UYzmwlcBAwys19FbMoDmjra191fNbPhHRSZBfzJg4eKzzezPmY2ABgOrHf3\nDWEM94dlV3ZclcQxrn8uXz5zBHfN28CXzhjOhAF58Q5JROSYHa6FsR0oBeqAhRHLY8DHjvG7BwFb\nIz6XhevaW9+tfG36aHLTU/jpM2viHYqISKfosIXh7kuAJWb2V3dvBDCzvsAQd9/XFQEejpnNJujS\nYujQoXGO5n35WalcfcYIfvnCOrbvr2Vgn8x4hyQickyivYbxnJnlmVkBsAi4y8x+fozfvQ0YEvF5\ncLiuvfVtcvc73X2Ku08pKio6xpA61yUnBQ0j3ZchIj1BtAkj390PAJ8iuO4wDfjoMX73Y8BV4Wip\nU4FKd98BLADGmNkIM0sDLgvLdjvDC7M5YVA+jy3ZTnCpRkSk+4o2YaSEF6Q/CzwezQ5mdh/wJjDO\nzMrM7Bozm2Nmc8IiTwIbgPXAXcB1AO7eBFwPPAOsAh5w9xXRVijRfPYjQ1i2rZLnVu6KdygiIsek\nw2sYEW4m+AF/3d0XmNlIYF1HO7j75YfZ7sDX2tn2JEFC6fYu/8gQ7n1zMz98YiXnji8mNVn3SopI\n9xTVr5e7/83dJ7n7teHnDe7+6diG1jOkJCfx7Y+NY+veWp5doVaGiHRf0d7pPdjMHg7v3C43swfN\nbHCsg+spzhtfzNCCLOa+sTHeoYiIHLVo+0f+QHDheWC4/D1cJ1FITjKuOm0YCzbtY/m2yniHIyJy\nVKJNGEXu/gd3bwqXuUBijWFNcJ+ZMoSstGRueWIVf3lLExOKSPcTbcKoMLMvmFlyuHwBqIhlYD1N\nfmYqnzllMG9uqOC7Dy9n457qeIckInJEok0YXyYYUrsT2AFcCnwpRjH1WDfOnMAvL5sMwCtryuMc\njYjIkYk2YdwMfNHdi9y9mCCB/GfswuqZMtOSmTV5ECMKs3llrR7jKiLdS7QJY1Lk3FHuvhc4KTYh\n9XznjC3ijXcrlDREpFuJNmEkhZMOAhDOKRXtTX/SyjVnjmBYvyyumbuA8gN18Q5HRCQq0SaMnwFv\nmtkPzeyHwBvArbELq2cbUpDFry8/maYW54XVupYhIt1DtHd6/4lg4sFd4fIpd/9zLAPr6caW5DCk\nIJP7F2xl/gYNOBORxBf1xEbuvtLdfxMu3ebpd4nKzPjo+BKWbN3PZXfOZ946Xc8QkcSmmfDi6Ktn\nj+Tr541mcN9MfvTkalpaNAW6iCQuJYw4GtQnk29dOI5vXziOVTsO8IpaGSKSwJQwEsBFJwygKDed\ne9/UlCEikriUMBJAWkoSl31kCC+uKdeUISKSsJQwEsSVpw0jPSWJXzy/VvdmiEhCUsJIEMW5GVx5\n6jAeXbydU//fC5Ru2hvvkEREPiCmCcPMZpjZGjNbb2Y3trH9X81scbgsN7Pm8C5yzGyTmS0Lt5XG\nMs5E8Y3zx3LzrOMoyk3nv55YRfAUWxGRxBCzhGFmycBtwExgInC5mU2MLOPuP3H3ye4+GbgJeCWc\np+qQc8PtU2IVZyLJSU/hqtOG860LxrF4635eWKW7wEUkccSyhTEVWB8+/7sBuB+Y1UH5y4H7YhhP\nt/GpkwcxuG8mt7+8Xq0MEUkYsUwYg4CtEZ/LwnUfYmZZwAzgwYjVDjxvZgvNbHZ7X2Jms82s1MxK\nd+/uGfcxpCQnMfvskSzasp+/lZbFOxwRESBxLnp/Ani9VXfUmWFX1Uzga2Z2dls7uvud7j7F3acU\nFfWcp8ZePnUoZ40p5KaHl/HE0h3xDkdEJKYJYxswJOLz4HBdWy6jVXeUu28LX8uBhwm6uHqN1OQk\nbr/iZE4a0oev37eIl/WEPhGJs1gmjAXAGDMbYWZpBEnhsdaFzCwfOAd4NGJdtpnlHnoPXAgsj2Gs\nCSk3I5U/XTOVMcW5fOuBJWypqIl3SCLSi8UsYbh7E3A98AywCnjA3VeY2RwzmxNR9BLgWXePvMW5\nBHjNzJYAbwNPuPvTsYo1kWWlpXDbFSfR1OJ8+o43WLG9Mt4hiUgvZT1pFM6UKVO8tLRn3rKxvryK\nq37/NgfqmvjLV6Zx4pA+8Q5JRHoAM1sY7a0LiXLRWw5jdHEuD153On2yUvnqn0rZWanpQ0Skaylh\ndCMD8jO5+4tTqK5vYvafS6lrbI53SCLSiyhhdDPj++fxi8tOYtm2Sr778HLd2CciXSYl3gHIkbtg\nYglfP28Mv3phHUkGV58xgokD8+Idloj0cGphdFPf+OgYrps+iofe2cZFv5rHvfP18CURiS0ljG4q\nOcn4zozxvHHjeUwbUcDPnl1DZU1jvMMSkR5MCaObK8nL4HufmEhlbSOX3P46i7bsi3dIItJDKWH0\nAMcNzOfP10yjvqmFS3/7Bn9fsj3eIYlID6SE0UOcMbqQp795FicM7sN//n0FlbWN1DU2axSViHQa\nJYweJDcjlVs+eTx7qxv43O/eZPLNz3L7y+/GOywR6SGUMHqY4wfl85vPn8ymimqSzLjz1Q1U1zfF\nOywR6QGUMHqgi04YwKL/uIA/XzONytpGrp67gKeX76C5Rd1TInL0lDB6qKy0FE4Z1pd/u2g82/bV\nMufeRVz/10U0NbfEOzQR6aaUMHq42WeP4tXvnMsNM8bz1PKd/PDxlbS0uC6Gi8gR09QgvUByknHt\n9FHsOVjP71/byIOLtvHJkwbyX588Id6hiUg3ooTRi9wwYzxl+2rYXFHDvfO3cNKQvlxwXAl5Ganx\nDk1EugE9QKkXqq5vYuYv57Flbw3pKUn88wVjmXPOqHiHJSJxcCQPUFILoxfKTk/h6W+exeKt+7nn\ntU38+KnVpCQZHzuuPwXZaWSn65+FiHxYTC96m9kMM1tjZuvN7MY2tk83s0ozWxwu34t2Xzk2WWkp\nnD6qkNuuOIkzRvfjv55YxVm3vsRx33+GW55YGe/wRCQBxexPSTNLBm4DLgDKgAVm9pi7t/41mufu\nFx/lvnKM0lOSufeaaby9cS+b99bw7Iqd/OH1TXz1rJEU52XEOzwRSSCx7HuYCqx39w0AZnY/MAuI\n5kf/WPaVI2RmTBvZj2kj+zF1eAHPr3qZq+cuoCg3nU9MGsiJQ/KpqmvipKF94x2qiMRRLBPGIGBr\nxOcyYFob5U43s6XANuDb7r7iCPbFzGYDswGGDh3aCWH3bsMLs7nkpEG8+W4FVXVNfOfBpeRmpNDc\n7Lxx03nkakSVSK8V76ubi4Ch7n7QzC4CHgHGHMkB3P1O4E4IRkl1foi9z88/NxmAfdUNfPR/XqGq\nrpHGZufP8zfz5TNGkJxkpCbrnk+R3iaWCWMbMCTi8+Bw3Xvc/UDE+yfN7HYzK4xmX4m9vtlp/PHq\nqRysb+K2l9Zz69Nr+Nmza+mblcadV53CyeqiEulVYpkwFgBjzGwEwY/9ZcDnIwuYWX9gl7u7mU0l\nGLVVAew/3L7SNU4YnA/AxIF5PLSojN1V9Ty+dAdX3v0WN140gbyMFGZNHhTnKEWkK8QsYbh7k5ld\nDzwDJAP3uPsKM5sTbr8DuBS41syagFrgMg/uJGxz31jFKoeXn5nK1WeMAOCLpw/nktte5z8eWQ5A\nkhkfP2EASUkWzxBFJMZ0p7cclbJ9NazZWcUvX1jH0rJKhvfL4i9fPZVBfTJpbnH2VjdQlJse7zBF\n5DB0p7fE3OC+WQzum8Upw/ry2JLt/OTpNXz2jjeZc85Inlq+k3e27OeV70ynOFf3coj0FBrqIsek\nT1YaV502nD9eM5XcjBT+49EVzN9QQW1jMw8ten+cQkuLs7OyLo6RisixUpeUdBp3Z1NFDanJxjfv\nX8yK7Qfol5PGzz5zIj99dg0LNu3jx586gcum6n4ZkURxJF1SamFIpzEzRhRmM7hvFnPOGcXgvplU\n1jTyuTvns3pHFScN7cNNDy+jdNPeeIcqIkdBCUNi4vyJJTz3L+fwi8smM3VEAQ9edzp/+co0BuZn\ncuNDy3h6+Q499U+km1HCkJj66IQSHvjH0xhbkktWWgq3XHI8ZftqmHPvIu6at4F91Q3MfX0jNQ1N\n8Q5VRA5D1zCkyzU2t/BP973Dsyt3UZybzo7KOqaOKGBLRQ3/csFYPvuRIYc/iIh0Cl3DkISWmpzE\nrZdO4oppQ0lPSeKCiSW8vXEvNQ3BZIePLt7GvuoGfvzUajZXVMc7XBEJqYUhcdfY3MKLq8s5a0wh\nV/7+bdbuqqIgO43NFTUMyM/g/649nUF9MuMdpkiPpBaGdCupyUl87Lj+ZKWl8NPPnMioohz6ZKVx\nyyXHU1XXxLcfWEJLi1Pf1MwfXt/IrgO6n0MkHnSntySUEYXZPPK1M977nJJk3PDgMi761TxSko3l\n2w5Qunkft33+5DhGKdI7qYUhCe2zU4Zw66cnkZuRQn1jC6eOLODJZTv485ubqDhYH+/wRHoVXcOQ\nbmVvdQMX/2oe2yvryElP4bpzR/HlM0aQkZr8obItLY5ZcEOhiLTtSK5hKGFIt9PY3MLaXVX8/Ll1\nPL9qF4P6ZHLOuCIKc9Ipyklj0uA+pKUkce29CzlrTBE//OTx8Q5ZJGFptlrp0VKTkzhuYD53f3EK\nb75bwc+fX8szy3eyt6aB1n//bN67mUtOHqSnA4p0ArUwpMdoam5hz8EG3tpYwYHaRk4e1pcrf/82\ne6sb+PgJA/ifz51IesqHu65EejN1SYmEtu6t4a9vb+G3L7/LwPwMJg7MJ8ngtFH93nuCoEhvpi4p\nkdCQgixumDGeEwf34dHF29i4p5qD9U08u3IX72zZT0V1PTv213He+GJumDme1ORg4GBdYzNVdU16\naqBIhJi2MMxsBvBLgudy3+3uP261/QrgBsCAKuBad18SbtsUrmsGmqLJgGphSDRaWpybH1/JgwvL\nyMtMZVz/XF5cXc6QgkxGFuZw3MA8XlhVzt6aBl674Vx1Y0mPlhBdUmaWDKwFLgDKgAXA5e6+MqLM\n6cAqd99nZjOBH7j7tHDbJmCKu++J9juVMORIHPq3b2Y8ungbTyzdwfbKWlZuPwBAi8OnThpEn6w0\nbpw5nsraRrU4pMdJlC6pqcB6d98QBnU/MAt4L2G4+xsR5ecDg2MYj8gHRN6fMWvyIGZNHgTA9v21\n1DQ0cfXcBTz0TvCY2aeX72BfTSM3zBhH2b5a/vmCsaQmJ7HnYD0DNc+V9BKxTBiDgK0Rn8uAaR2U\nvwZ4KuKzA8+bWTPwO3e/s62dzGw2MBtg6FA9+lOO3aEEcMOM8by4upyyvbWUbt5LbkYqP/h78PfO\nC6vLSTLYXFHDA3NOo7KmkXPGFlHb2MxbGyuYPraYpCTdMCg9S0Jc9DazcwkSxpkRq890921mVgw8\nZ2ar3f3V1vuGieROCLqkuiRg6RUunjSQiycN5EBdI1v31uAOL68pZ2xJLr97dQPV9U1kpibzmTve\npLnFOWtMIbUNzZRu3sfXzh3Fty8cx+6D9TQ0tXDz31dy86zj6Z+fEe9qiRy1WCaMbUDkk3AGh+s+\nwMwmAXcDM9294tB6d98Wvpab2cMEXVwfShgisZaXkcpxA/MBOH5Q8Hrhcf0BuHveBm59Zg1XnjqM\nhxaVUVXfxNQRBdz20ru8tm4PS8oqGd8/l9U7q8jNSOVnnz0xbvUQOVaxvOidQnDR+6MEiWIB8Hl3\nXxFRZiifCXz8AAAQHUlEQVTwInBV5PUMM8sGkty9Knz/HHCzuz/d0XfqorfEQ01DE1lpKTQ2t1Bx\nsIHCnDS++/By/rd0K0W56eyuqqcgO4291Q0M75fFddNHs/tgPZ+fOpTcjBRSkjUHqMRPQoySCgO5\nCPgFwbDae9z9FjObA+Dud5jZ3cCngc3hLk3uPsXMRgIPh+tSgL+6+y2H+z4lDEkU7s6egw0crG/i\n1y+u4xsfHcMDpVt5YVU5q3dWATC+fy6bKqr54unDOX9CCcP6ZVGcG3RZvbS6nFufWcM3zx/Dx8LW\njEgsJEzC6GpKGJLoahuaeeidMvZUNfDz59cyMD+D7ZXvPxDqEycO5IRBefzoydUAnDg4n/tmn0pq\nctJ7NxWKdCYlDJEE5+4s2rKf4wflsWRrJTUNTby1cS+/n7eRhuYWpo0o4Nzxxfz4qdWkJhv5manc\nOHMCWWnJZKYlc/KQvlTWNlKYm0ZWWnApcuX2A+RmpDCkICvOtZPuRAlDpJvaX9PA6p1VTB7Sh/rG\nFs7+yUtMHJBHY3MLpZv3fah8fmYqxw3MoyQvg8eXbqcgO42/X38mRbnpeg6IREUJQ6SHqK5vIist\nmYbmFn7x/DrGlgTPO1+3q4qstBTmb6hg+/5aVu2oYnRxDmt3VVHf1MJpI/vxjfPHMLhvJoP7qsUh\n7VPCEOll6puaSUlKYknZfl5YtYu75m2koamFtOQkLjiuhOy0ZPZWN5KRmkRxbgZJBnOmj6IwJ526\nxmb21TQwIF93rPdGShgivdz68oNs3FPNU8t2sHDLPhqaWshOT2FvdQMH65pocSfJjHPGFbGlooaN\ne6q5ceZ4BvXNpLyqnlmTB5KXkdru8avrm8hOT4j7fuUYKWGISJsam1tobnHK9tVy/9tbePidbdQ3\ntTC+f+4HrpGkpSQxvn8uo4py+NTJg1i+7QB/W7iVH846ni17a/jBYyv4zedP5o139/Cl04czrF92\nHGslx0IJQ0SiUtfYTF1jM3kZqazYfoDK2kZyM1J4fOl2Vu+sYmlZJZW1jQDkZqRQXd9ERmoyNQ3N\nmIF7kFymjSjgtFH9uPSUwe/dSyLdgxKGiHSK2oZm3tywh8Zm54zRhdz00DKeWbGTmcf359HF2/n2\nhWPZc7CB+RsqWL2zivSUJL594Tjys1IZ3DeTMcW5HKhrJCM1maq6Rua/W8HMEwZQkqekkiiUMEQk\nZg61MpZvq2TS4Pz3hu9u2lPN9x9bwStrd3e4/5CCTM6fUEJxbgZ9slLJTE2mf34Gc1/fRHVDE9ee\nM4rTRxd+YB931zDhGFHCEJG4aG5xFm7eR7+cNMr21bK+/CAF2anUN7aQnppEfmYq//HICvbXNFDd\n0PyBfXPSU8jLSKGytpGbLprAmaMLKchJ4xv3vcPr71YwqiiHfzx7JB+fNEB3vXciJQwRSXhVdY0c\nrG+iur6JFdsPcMqwvqQkJfHp377Btv21mEF2Wgp1jc18ftpQ3ny3gnXlBxnUJ5OPTihmYJ9MRhZm\n84ewZXLd9NFMGd6X7LQg6ZTktX3zYkuL8+CiMtaVH+TGGeN7/XNLlDBEpNtqaGph+/5a/r5kOzsO\n1HHxCQM4fXQhLS3OS2vKuWveBlZuP8CBuiYAMlOTyc1IobyqnozUJLLSguHD4/vncsPM8Qzqk8nm\nihr2VtfzDycO4nuPLudvC8sAuOMLpzDj+A9O7tjc4mzdW8PwwiMb+dXc4tzz2kZmnTSwW134V8IQ\nkR6vsqaRteVVDOyTSUFWGsu3V3Lf21uoqmti2ogC7pq3gV0H6j+wT0qS0dTiXDd9FE8u20Fjs3Pa\nqH4MyM9geL9sThicz61Pr+b5VeX86JITOHtsIYP7ZtHY3EJKknV4HeWl1eVcPXcBXzlzBP9+8cRY\nV7/TKGGISK9XVdfI4q37qaxtJCc9hYzUZF5es5uSvHS+dPpwnl25ix89uYr6xhbKq+poCX8KzWBk\nYTbv7q4GYHDfTMr21ZKdlswXThtG/7wMFm/dz7j+uWSnpbCpoprBfbN4bd1uXlqzm8KcdObfdF63\nec6JEoaIyBFoam5h1Y4qVu6o5CPDCyjKTeepZTvZV9PAmxsqmDggj80VNTyxbAfAew/EAkhPSaK+\nqQWA0cU5rC8/yMQBedQ3NTO8Xzb5WcFF/6Xb9jOmOJdzxxczriSX8qo6tu+v5ZRhfTllWAEQdMft\nr2kgMy2ZA3VN5KSlkJ/V/h33nUEJQ0QkBvZWN1Df1Ez/vAwqaxtpaG6hKCed9eUH+dvCMq48dRi/\nfnEdOyrryEpL5t3d1dQ1NpOSZIwuzmFpWSXlVfUfOu6kwfnkZqTwzpb91ESMHktPSeKcsUXkZ6Zi\nBmNLchlbkktNQxM56akM65dFZW0j72zZx5WnDT+qOilhiIgkIHdne2Uda3dW0S8njcF9s/hb6VZe\nXF1OfVMLEwfmMWFA3nuzFK/aUcVbGyuoqW+mxb3NZGMGJbkZvPjtc957NsqRSJiEYWYzgF8SPKL1\nbnf/cavtFm6/CKgBvuTui6LZty1KGCLSk23cU82uA3XkZaRysL6J0s17qWts4ZozR5CfeXRdV0eS\nMGI23aSZJQO3ARcAZcACM3vM3VdGFJsJjAmXacBvgWlR7isi0quMKMxmRMRw36kjCrr0+2N5GX8q\nsN7dN7h7A3A/MKtVmVnAnzwwH+hjZgOi3FdERLpQLBPGIGBrxOeycF00ZaLZV0REulD3GCjcATOb\nbWalZla6e3fHk56JiMjRi2XC2AYMifg8OFwXTZlo9gXA3e909ynuPqWoqOiYgxYRkbbFMmEsAMaY\n2QgzSwMuAx5rVeYx4CoLnApUuvuOKPcVEZEuFLNRUu7eZGbXA88QDI29x91XmNmccPsdwJMEQ2rX\nEwyrvbqjfWMVq4iIHJ5u3BMR6cWO5D6Mbn/RW0REukaPamGY2W5g81HuXgjs6cRw4kl1STw9pR6g\nuiSqo63LMHePasRQj0oYx8LMSqNtliU61SXx9JR6gOqSqLqiLuqSEhGRqChhiIhIVJQw3ndnvAPo\nRKpL4ukp9QDVJVHFvC66hiEiIlFRC0NERKKihCEiIlHp9QnDzGaY2RozW29mN8Y7niNlZpvMbJmZ\nLTaz0nBdgZk9Z2brwte+8Y6zLWZ2j5mVm9nyiHXtxm5mN4XnaY2ZfSw+Ubetnbr8wMy2hedmsZld\nFLEtkesyxMxeMrOVZrbCzL4Rru9W56aDenS782JmGWb2tpktCevyn+H6rj0n7t5rF4J5qt4FRgJp\nwBJgYrzjOsI6bAIKW627FbgxfH8j8N/xjrOd2M8GTgaWHy52YGJ4ftKBEeF5S453HQ5Tlx8A326j\nbKLXZQBwcvg+F1gbxtytzk0H9eh25wUwICd8nwq8BZza1eekt7cweuqT/WYBfwzf/xH4ZBxjaZe7\nvwrsbbW6vdhnAfe7e727bySYsHJqlwQahXbq0p5Er8sOd18Uvq8CVhE8wKxbnZsO6tGehKwHgAcO\nhh9Tw8Xp4nPS2xNGT3iynwPPm9lCM5sdrivxYJp4gJ1ASXxCOyrtxd5dz9XXzWxp2GV1qLug29TF\nzIYDJxH8Rdttz02rekA3PC9mlmxmi4Fy4Dl37/Jz0tsTRk9wprtPBmYCXzOzsyM3etA+7ZZjp7tz\n7KHfEnR3TgZ2AD+LbzhHxsxygAeBb7r7gcht3enctFGPbnle3L05/H99MDDVzI5vtT3m56S3J4yo\nn+yXqNx9W/haDjxM0OzcZWYDAMLX8vhFeMTai73bnSt33xX+T94C3MX7XQIJXxczSyX4kf2Luz8U\nru5256atenTn8wLg7vuBl4AZdPE56e0Jo1s/2c/Mss0s99B74EJgOUEdvhgW+yLwaHwiPCrtxf4Y\ncJmZpZvZCGAM8HYc4ovaof+RQ5cQnBtI8LqYmQG/B1a5+/9EbOpW56a9enTH82JmRWbWJ3yfCVwA\nrKarz0m8r/7HeyF44t9aglEE3413PEcY+0iCkRBLgBWH4gf6AS8A64DngYJ4x9pO/PcRdAk0EvSx\nXtNR7MB3w/O0BpgZ7/ijqMufgWXA0vB/4AHdpC5nEnRtLAUWh8tF3e3cdFCPbndegEnAO2HMy4Hv\nheu79JxoahAREYlKb++SEhGRKClhiIhIVJQwREQkKkoYIiISFSUMERGJihKGJDwzeyN8HW5mn+/k\nY/9bW98VK2b2STP7XoyO/W+HL3XExzzBzOZ29nGle9KwWuk2zGw6wSyjFx/BPinu3tTB9oPuntMZ\n8UUZzxvAP7j7nmM8zofqFau6mNnzwJfdfUtnH1u6F7UwJOGZ2aFZOn8MnBU+w+Cfw8nYfmJmC8KJ\n5P4xLD/dzOaZ2WPAynDdI+EEjSsOTdJoZj8GMsPj/SXyuyzwEzNbbsHzRj4XceyXzez/zGy1mf0l\nvKMYM/uxBc9eWGpmP22jHmOB+kPJwszmmtkdZlZqZmvN7OJwfdT1ijh2W3X5ggXPUFhsZr8zs+RD\ndTSzWyx4tsJ8MysJ138mrO8SM3s14vB/J5gFQXq7eN/BqEXL4RbgYPg6HXg8Yv1s4N/D9+lAKcHc\n/9OBamBERNmC8DWT4E7ZfpHHbuO7Pg08R/DMlBJgC8HzFaYDlQRz8yQBbxLcUdyP4I7aQ632Pm3U\n42rgZxGf5wJPh8cZQ3CHeMaR1Kut2MP3Ewh+6FPDz7cDV4XvHfhE+P7WiO9aBgxqHT9wBvD3eP87\n0BL/JSXaxCKSgC4EJpnZpeHnfIIf3gbgbQ+eA3DIP5nZJeH7IWG5ig6OfSZwn7s3E0zw9grwEeBA\neOwyAAummx4OzAfqgN+b2ePA420ccwCwu9W6BzyYBG+dmW0Axh9hvdrzUeAUYEHYAMrk/YnpGiLi\nW0gwLxHA68BcM3sAeOj9Q1EODIziO6WHU8KQ7syAr7v7Mx9YGVzrqG71+XzgNHevMbOXCf6SP1r1\nEe+bgRR3bzKzqQQ/1JcC1wPntdqvluDHP1Lri4hOlPU6DAP+6O43tbGt0d0PfW8z4e+Au88xs2nA\nx4GFZnaKu1cQ/LeqjfJ7pQfTNQzpTqoIHrV5yDPAtRZMYY2ZjQ1n7W0tH9gXJovxBI+2PKTx0P6t\nzAM+F15PKCJ4BGu7s31a8MyFfHd/Evhn4MQ2iq0CRrda9xkzSzKzUQSTSa45gnq1FlmXF4BLzaw4\nPEaBmQ3raGczG+Xub7n79whaQoemxx7L+zO6Si+mFoZ0J0uBZjNbQtD//0uC7qBF4YXn3bT9ONqn\ngTlmtorgB3l+xLY7gaVmtsjdr4hY/zBwGsFMwA58x913hgmnLbnAo2aWQfDX/b+0UeZV4GdmZhF/\n4W8hSER5wBx3rzOzu6OsV2sfqIuZ/TvwrJklEcyi+zVgcwf7/8TMxoTxvxDWHeBc4Ikovl96OA2r\nFelCZvZLggvIz4f3Nzzu7v8X57DaZWbpwCsET3Zsd3iy9A7qkhLpWj8CsuIdxBEYCtyoZCGgFoaI\niERJLQwREYmKEoaIiERFCUNERKKihCEiIlFRwhARkaj8f1wep5AzuiGrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f6c28b1e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.997222\n",
      "Test Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<table> \n",
    "    <tr> \n",
    "        <td>\n",
    "            **Train Accuracy**\n",
    "        </td>\n",
    "        <td>\n",
    "        0.997222\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr> \n",
    "        <td>\n",
    "            **Test Accuracy**\n",
    "        </td>\n",
    "        <td>\n",
    "        0.8\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "**Insights**:\n",
    "- Our model seems big enough to fit the training set well. \n",
    "- However, given the difference between train and test accuracy, we could try to add L2 or dropout regularization to reduce overfitting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color='blue'>\n",
    "**Things to remember**:\n",
    "- Tensorflow is a programming framework used in deep learning\n",
    "- The two main object classes in tensorflow are Tensors and Operators. \n",
    "- When we code in tensorflow we have to take the following steps:\n",
    "    - Create a graph containing Tensors (Variables, Placeholders ...) and Operations (tf.matmul, tf.add, ...)\n",
    "    - Create a session\n",
    "    - Initialize the session\n",
    "    - Run the session to execute the graph\n",
    "- WE can execute the graph multiple times as you've seen in model()\n",
    "- The backpropagation and optimization is automatically done when running the session on the \"optimizer\" object."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "deep-neural-network",
   "graded_item_id": "BFd89",
   "launcher_item_id": "AH2rK"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
